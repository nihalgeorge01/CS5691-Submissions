{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3 Part B -- DTW and HMM\n",
    "\n",
    "# CWRT DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train and Dev MFCCs\n",
    "# Structure of train_mfcc and dev_mfcc = {digit:{filename:np_array_of_MFCC}}\n",
    "INF = 9999999\n",
    "digits = [2,4,6,8,9]\n",
    "train_mfcc = {}\n",
    "dev_mfcc = {}\n",
    "\n",
    "for dig in digits:\n",
    "    train_path = f\"./IsolatedDigits/{dig}/train/\"\n",
    "    dev_path = f\"./IsolatedDigits/{dig}/dev/\"\n",
    "    \n",
    "    # Train MFCCs\n",
    "    train_fps = os.listdir(train_path)\n",
    "    mfcc_fps = [fp for fp in train_fps if fp[len(fp)-4:len(fp)] == 'mfcc']\n",
    "    train_mfcc[dig] = {}\n",
    "    for fp in mfcc_fps:\n",
    "        fn = fp.split('.')[0]\n",
    "        train_mfcc[dig][fn] = np.loadtxt(train_path+fp, skiprows=1)\n",
    "    \n",
    "    # Dev MFCCs\n",
    "    dev_fps = os.listdir(dev_path)\n",
    "    mfcc_fps = [fp for fp in dev_fps if fp[len(fp)-4:len(fp)] == 'mfcc']\n",
    "    dev_mfcc[dig] = {}\n",
    "    for fp in mfcc_fps:\n",
    "        fn = fp.split('.')[0]\n",
    "        dev_mfcc[dig][fn] = np.loadtxt(dev_path+fp, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([2, 4, 6, 8, 9]) dict_keys(['ac_2', 'ag_2', 'ai_2', 'an_2', 'bh_2', 'bi_2', 'br_2', 'ca_2', 'cg_2', 'cl_2', 'cm_2', 'dc_2', 'dg_2', 'ea_2', 'ec_2', 'ee_2', 'eg_2', 'ei_2', 'ek_2', 'es_2', 'hg_2', 'hp_2', 'ig_2', 'ih_2', 'il_2', 'jc_2', 'ji_2', 'jj_2', 'jn_2', 'jp_2', 'kc_2', 'kf_2', 'kh_2', 'kk_2', 'kn_2', 'kt_2', 'la_2', 'ld_2', 'ls_2'])\n"
     ]
    }
   ],
   "source": [
    "# TODO Remove\n",
    "print(train_mfcc.keys(), train_mfcc[2].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(v1,v2,angle=False):\n",
    "    '''\n",
    "    Computes cost of difference between two vectors\n",
    "    '''\n",
    "\n",
    "    if not angle:\n",
    "        return np.linalg.norm(v1-v2)\n",
    "    else:\n",
    "        diff = v2-v1\n",
    "        # diff[np.where(diff>np.pi)] -= 2*np.pi\n",
    "        # diff[np.where(diff<-np.pi)] += 2*np.pi\n",
    "        if diff > np.pi:\n",
    "            diff -= 2*np.pi \n",
    "        if diff < -np.pi:\n",
    "            diff += 2*np.pi\n",
    "        return np.abs(diff)\n",
    "\n",
    "def dtw(x, y, angle=False):\n",
    "    '''\n",
    "    Computes DTW between sequences of MFCC vectors x and y \n",
    "    '''\n",
    "    \n",
    "    XLEN = len(x)\n",
    "    YLEN = len(y)\n",
    "    \n",
    "    dp = [[INF for j in range(YLEN+1)] for i in range(XLEN+1)]\n",
    "    dp[0][0] = 0\n",
    "\n",
    "    for i in range(1,XLEN+1):\n",
    "        for j in range(1,YLEN+1):\n",
    "            cost_here = cost(x[i-1], y[j-1], angle)\n",
    "            dp[i][j] = cost_here + min([dp[i-1][j], dp[i][j-1], dp[i-1][j-1]])\n",
    "    \n",
    "    return dp[-1][-1]\n",
    "\n",
    "def majorityVoting(lst):\n",
    "    data = Counter(lst)\n",
    "    return data.most_common(1)[0][0]\n",
    "\n",
    "def dtwWithPath(x,y, angle=False):\n",
    "    '''\n",
    "    Same as dtw() but also return the warped form of y wrt x\n",
    "    '''\n",
    "\n",
    "    XLEN = len(x)\n",
    "    YLEN = len(y)\n",
    "    \n",
    "    dp = [[[INF,i,j] for j in range(YLEN+1)] for i in range(XLEN+1)]\n",
    "    dp[0][0] = [0,None,None]\n",
    "\n",
    "    # Find DTW Matrix\n",
    "    for i in range(1, XLEN+1):\n",
    "        for j in range(1, YLEN+1):\n",
    "            c = cost(x[i-1], y[j-1], angle)\n",
    "            dp[i][j] = min([ [dp[i-1][j][0]+c, i-1, j], [dp[i][j-1][0]+c, i, j-1], [dp[i-1][j-1][0]+c, i-1, j-1]  ])\n",
    "\n",
    "    # Extract Path\n",
    "    curr = [XLEN, YLEN]\n",
    "    path = [curr.copy()]\n",
    "    dirs = []\n",
    "    next = dp[curr[0]][curr[1]][1:]\n",
    "\n",
    "    # ct = 0\n",
    "    while next[0] != None and next[1] != None: \n",
    "        if next[0] < curr[0] and next[1] < curr[1]:\n",
    "            dirs.append('J')\n",
    "        elif next[1] < curr[1]:\n",
    "            dirs.append('R')\n",
    "        else:\n",
    "            dirs.append('D')\n",
    "\n",
    "        path.append(next.copy())\n",
    "        curr = next.copy()\n",
    "        next = dp[curr[0]][curr[1]][1:]\n",
    "\n",
    "    path = path[::-1][1:]\n",
    "    dirs = dirs[::-1][1:]\n",
    "    \n",
    "    # R : avg from curr to curr+runlength(R) inclusive\n",
    "    # D : interp between curr and curr+runlength(D) inclusive, runlength(D) times\n",
    "\n",
    "    # CWRT\n",
    "    # Resolve all Rs first, they are avgs and their endpoints dont change\n",
    "    # Then resolve Ds using the updated endpoints. Helps in case of ...DR...\n",
    "    \n",
    "    # Resolving Rs\n",
    "    new_dirs = []\n",
    "    warped_y = []\n",
    "    R_run = 0\n",
    "    D_run = 0\n",
    "    ptr = 0\n",
    "    for dir_ind in range(len(dirs)):\n",
    "        dir = dirs[dir_ind]\n",
    "        if dir == 'J':\n",
    "            new_dirs.append('J')\n",
    "            if R_run != 0:\n",
    "                warped_y.append(np.mean(y[ptr-R_run:ptr+1], axis=0))\n",
    "                R_run = 0\n",
    "            elif D_run != 0:\n",
    "                warped_y.append(y[ptr])\n",
    "                D_run = 0\n",
    "            else:\n",
    "                warped_y.append(y[ptr])\n",
    "            ptr+=1\n",
    "        elif dir == 'R':\n",
    "            R_run += 1\n",
    "            ptr += 1\n",
    "        else: # dir == 'D'\n",
    "            D_run += 1\n",
    "            new_dirs.append('D')\n",
    "    if D_run != 0:\n",
    "        warped_y.append(y[ptr])\n",
    "        \n",
    "    elif R_run != 0:\n",
    "        warped_y.append(np.mean(y[ptr-R_run:ptr+1], axis=0))\n",
    "    \n",
    "    warped_y.append(y[-1])\n",
    "    dirs = new_dirs.copy()\n",
    "\n",
    "    # Resolving Ds\n",
    "    y = warped_y.copy()\n",
    "    warped_y = []\n",
    "    D_run = 0\n",
    "    ptr = 0\n",
    "    for dir_ind in range(len(dirs)):\n",
    "        dir = dirs[dir_ind]\n",
    "        if dir == 'J':\n",
    "            if D_run != 0:\n",
    "                interps = np.linspace(y[ptr], y[ptr+1], D_run+2)[:-1]\n",
    "                interps = [interps[ind] for ind in range(interps.shape[0])]\n",
    "                warped_y.extend(interps)\n",
    "                D_run = 0\n",
    "                ptr+=1\n",
    "            else:\n",
    "                warped_y.append(y[ptr])\n",
    "                ptr+=1\n",
    "        else: # dir == 'D'\n",
    "            D_run += 1\n",
    "    if D_run != 0:\n",
    "        interps = np.linspace(y[ptr], y[ptr+1], D_run+2)[:-1]\n",
    "        interps = [interps[ind] for ind in range(interps.shape[0])]\n",
    "        warped_y.extend(interps)\n",
    "        D_run = 0\n",
    "    else:\n",
    "        warped_y.append(y[-1])\n",
    "    \n",
    "    return dp[-1][-1], warped_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "warped y: [1, 4.0, 4.333333333333333, 4.666666666666667, 5, 9.5, 3, 2, 7.0, 4]\n"
     ]
    }
   ],
   "source": [
    "test_arr1 = np.array([1,7,3,4,1,10,5,4,7,4])\n",
    "test_arr2 = np.array([1,4,5,10,9,3,2,6,8,4])\n",
    "print(cost(test_arr1[1],test_arr2[1]))\n",
    "res = dtwWithPath(test_arr1, test_arr2)\n",
    "print(f\"warped y: {res[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemplates(train_mfcc, angle=False):\n",
    "    '''\n",
    "    Computes a reference template for each class using CWRT\n",
    "    '''\n",
    "\n",
    "    templ = {dig:None for dig in train_mfcc.keys()}\n",
    "    for dig in train_mfcc.keys():\n",
    "        \n",
    "        dig_fns = sorted(train_mfcc[dig].keys())\n",
    "        init_templ = train_mfcc[dig][dig_fns[0]]\n",
    "        warped_collection = [init_templ]\n",
    "        for fn in dig_fns[1:]:\n",
    "            mfcc_here = train_mfcc[dig][fn]\n",
    "            res = dtwWithPath(init_templ, mfcc_here, angle)\n",
    "            warped_mfcc_here = res[1]\n",
    "            \n",
    "            warped_collection.append(warped_mfcc_here)\n",
    "            \n",
    "        # print('shapes:', [len(arr) for arr in warped_collection])\n",
    "        new_templ = np.mean(np.array(warped_collection), axis=0)\n",
    "        templ[dig] = new_templ\n",
    "    \n",
    "    return templ\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Templates Built\n"
     ]
    }
   ],
   "source": [
    "# Warp kc of Nc train examples of class c to same audio, then average\n",
    "templ = getTemplates(train_mfcc)\n",
    "print(\"Templates Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute DTW error, get majority votes of top K, get class\n",
    "\n",
    "def predictCWRT(train_mfcc, dev_mfcc, angle=False):\n",
    "\n",
    "    t1 = time.time()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for dev_dig in dev_mfcc.keys():\n",
    "        for dev_fn in dev_mfcc[dev_dig].keys():\n",
    "            dev_frames = dev_mfcc[dev_dig][dev_fn]\n",
    "            print(f\"Dev {dev_fn} prediction: \", end = '')\n",
    "            \n",
    "            dig_best = None\n",
    "            err_best = INF\n",
    "            errs = []\n",
    "            for train_dig in train_mfcc.keys():\n",
    "                template = templ[train_dig]\n",
    "                err_here = dtw(template, dev_frames, angle)\n",
    "                if err_here < err_best:\n",
    "                    err_best = err_here\n",
    "                    dig_best = train_dig\n",
    "            \n",
    "            print(dig_best)\n",
    "            if dig_best == dev_dig:\n",
    "                correct+=1\n",
    "            else:\n",
    "                print(f\"Failed, true: {dev_dig}, pred: {dig_best}\")\n",
    "            \n",
    "            total += 1\n",
    "    \n",
    "    t2 = time.time()\n",
    "    acc = correct/total\n",
    "    print(f\"Acc: {acc}\")\n",
    "    print(\"Time taken: {:.4f} sec\".format(t2-t1))\n",
    "\n",
    "def predict(train_mfcc, dev_mfcc, angle=False):\n",
    "    t1 = time.time()\n",
    "    K = 5\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for dev_dig in dev_mfcc.keys():\n",
    "        for dev_fn in dev_mfcc[dev_dig].keys():\n",
    "            dev_frames = dev_mfcc[dev_dig][dev_fn]\n",
    "            print(f\"Dev {dev_fn} prediction: \", end = '')\n",
    "            \n",
    "            dig_best = None\n",
    "            err_best = INF\n",
    "            errs = []\n",
    "            for train_dig in train_mfcc.keys():\n",
    "            \n",
    "                for train_fn in train_mfcc[train_dig].keys():\n",
    "                    \n",
    "                    train_frames = train_mfcc[train_dig][train_fn]\n",
    "                    err_here = dtw(train_frames, dev_frames, angle)\n",
    "                    errs.append([err_here, train_dig])\n",
    "            \n",
    "            topK = sorted(errs)[:K]\n",
    "            topK_digs = [val[1] for val in topK]\n",
    "            dig_best = majorityVoting(topK_digs)\n",
    "            \n",
    "            print(dig_best)\n",
    "            if dig_best == dev_dig:\n",
    "                correct+=1\n",
    "                print(\"Passed, votes:\", topK_digs)\n",
    "            else:\n",
    "                print(\"Failed, votes:\", topK_digs)\n",
    "            total += 1\n",
    "    \n",
    "    t2 = time.time()\n",
    "    acc = correct/total\n",
    "    print(f\"Acc: {acc}\")\n",
    "    print(\"Time taken: {:.4f} sec\".format(t2-t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev mk_2 prediction: 2\n",
      "Dev mm_2 prediction: 2\n",
      "Dev ms_2 prediction: 2\n",
      "Dev mw_2 prediction: 2\n",
      "Dev nc_2 prediction: 2\n",
      "Dev ng_2 prediction: 2\n",
      "Dev nh_2 prediction: 2\n",
      "Dev pe_2 prediction: 2\n",
      "Dev pk_2 prediction: 2\n",
      "Dev pm_2 prediction: 2\n",
      "Dev pp_2 prediction: 2\n",
      "Dev ra_2 prediction: 2\n",
      "Dev mk_4 prediction: 4\n",
      "Dev mm_4 prediction: 4\n",
      "Dev ms_4 prediction: 4\n",
      "Dev mw_4 prediction: 4\n",
      "Dev nc_4 prediction: 4\n",
      "Dev ng_4 prediction: 4\n",
      "Dev nh_4 prediction: 4\n",
      "Dev pe_4 prediction: 4\n",
      "Dev pk_4 prediction: 4\n",
      "Dev pm_4 prediction: 4\n",
      "Dev pp_4 prediction: 4\n",
      "Dev ra_4 prediction: 4\n",
      "Dev mk_6 prediction: 6\n",
      "Dev mm_6 prediction: 6\n",
      "Dev ms_6 prediction: 6\n",
      "Dev mw_6 prediction: 6\n",
      "Dev nc_6 prediction: 6\n",
      "Dev ng_6 prediction: 6\n",
      "Dev nh_6 prediction: 6\n",
      "Dev pe_6 prediction: 6\n",
      "Dev pk_6 prediction: 6\n",
      "Dev pm_6 prediction: 6\n",
      "Dev pp_6 prediction: 6\n",
      "Dev ra_6 prediction: 6\n",
      "Dev mk_8 prediction: 8\n",
      "Dev mm_8 prediction: 8\n",
      "Dev ms_8 prediction: 8\n",
      "Dev mw_8 prediction: 8\n",
      "Dev nc_8 prediction: 8\n",
      "Dev ng_8 prediction: 8\n",
      "Dev nh_8 prediction: 8\n",
      "Dev pe_8 prediction: 8\n",
      "Dev pk_8 prediction: 8\n",
      "Dev pm_8 prediction: 8\n",
      "Dev pp_8 prediction: 8\n",
      "Dev ra_8 prediction: 8\n",
      "Dev mk_9 prediction: 9\n",
      "Dev mm_9 prediction: 9\n",
      "Dev ms_9 prediction: 9\n",
      "Dev mw_9 prediction: 9\n",
      "Dev nc_9 prediction: 9\n",
      "Dev ng_9 prediction: 9\n",
      "Dev nh_9 prediction: 9\n",
      "Dev pe_9 prediction: 9\n",
      "Dev pk_9 prediction: 9\n",
      "Dev pm_9 prediction: 9\n",
      "Dev pp_9 prediction: 9\n",
      "Dev ra_9 prediction: 9\n",
      "Acc: 1.0\n",
      "Time taken: 20.5280 sec\n"
     ]
    }
   ],
   "source": [
    "# predict(train_mfcc, dev_mfcc)\n",
    "predictCWRT(train_mfcc, dev_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Handwritten Character Recognition\n",
    "\n",
    "def loadHW(path, angle=False):\n",
    "    f = open(path, 'r')\n",
    "    data = f.readline().split()[1:]\n",
    "    data = [float(v) for v in data]\n",
    "    feats = []\n",
    "    for i in range(int(len(data)/2)):\n",
    "        feats.append(np.array([data[2*i], data[2*i + 1]]))\n",
    "    \n",
    "    if angle:\n",
    "        vecs = np.diff(np.array(feats), axis=0)\n",
    "        angles = np.arctan2(vecs[:,1], vecs[:,0])\n",
    "        return angles\n",
    "    else:\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['a', 'ai', 'bA', 'chA', 'dA']\n",
    "hwr_angle = True\n",
    "\n",
    "# Load Train and Dev MFCCs\n",
    "# Structure of train_mfcc and dev_mfcc = {digit:{filename:np_array_of_MFCC}}\n",
    "\n",
    "train_feats = {}\n",
    "dev_feats = {}\n",
    "\n",
    "for let in letters:\n",
    "    train_path = f\"./HandwritingData/{let}/train/\"\n",
    "    dev_path = f\"./HandwritingData/{let}/dev/\"\n",
    "    \n",
    "    # Train MFCCs\n",
    "    train_fps = os.listdir(train_path)\n",
    "    train_feats[let] = {}\n",
    "    for fp in train_fps:\n",
    "        fn = fp.split('.')[0]\n",
    "\n",
    "        feats_here = loadHW(train_path+fp, hwr_angle)\n",
    "        feats_here = np.array(feats_here)\n",
    "        # feats_here = feats_here - np.mean(feats_here, axis=0)\n",
    "        # feats_here = feats_here/np.sqrt(np.var(feats_here, axis=0))\n",
    "\n",
    "        train_feats[let][fn] = feats_here\n",
    "        # train_feats[let][fn] = loadHW(train_path+fp)\n",
    "    \n",
    "    # Dev MFCCs\n",
    "    dev_fps = os.listdir(dev_path)\n",
    "    dev_feats[let] = {}\n",
    "    for fp in dev_fps:\n",
    "        fn = fp.split('.')[0]\n",
    "\n",
    "        feats_here = loadHW(dev_path+fp, hwr_angle)\n",
    "        feats_here = np.array(feats_here)\n",
    "        # feats_here = feats_here - np.mean(feats_here, axis=0)\n",
    "        # feats_here = feats_here/np.sqrt(np.var(feats_here, axis=0))\n",
    "\n",
    "        dev_feats[let][fn] = feats_here\n",
    "        # dev_feats[let][fn] = loadHW(dev_path+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['a', 'ai', 'bA', 'chA', 'dA'])\n",
      "dict_keys(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '8', '9'])\n",
      "[-0.78532266  0.         -0.46367781  0.          0.          0.\n",
      "  0.46367781  0.78532266  0.98280534  0.78539816  1.57079633  1.57079633\n",
      "  3.14159265  2.67797525  3.14159265  3.14159265  3.14159265 -1.57079633\n",
      " -2.67791484 -2.35626999 -2.03441374 -2.35619449 -1.57079633 -2.35611899\n",
      " -1.57079633 -1.10717892 -1.57079633 -0.78539816 -0.78539816 -0.78547366\n",
      " -0.32172035  0.          0.         -0.24499643  0.          0.\n",
      "  0.          0.          0.24499643  0.32172035  0.24499643  0.58801422\n",
      "  0.46367781  0.98278211  0.78539816  1.10717892  1.57079633  1.57079633\n",
      "  1.57079633  1.57079633  3.14159265  2.35626999  3.14159265  3.14159265\n",
      "  3.14159265 -2.67797525 -2.35619449 -2.35619449 -1.57079633 -1.57079633\n",
      " -2.35619449 -1.57079633 -1.57079633 -2.35619449 -2.35619449  3.14159265\n",
      " -2.67797525 -2.35619449  3.14159265  3.14159265 -2.35626999  3.14159265\n",
      "  3.14159265  3.14159265  3.14159265  3.14159265  3.14159265  3.14159265]\n",
      "dict_keys(['a', 'ai', 'bA', 'chA', 'dA'])\n",
      "dict_keys(['70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89'])\n"
     ]
    }
   ],
   "source": [
    "print(train_feats.keys())\n",
    "print(train_feats['a'].keys())\n",
    "print(train_feats['a']['1'])\n",
    "\n",
    "print(dev_feats.keys())\n",
    "print(dev_feats['a'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just exploring the data\n",
    "if not hwr_angle:\n",
    "    eg_ct = 5\n",
    "    for let in train_feats.keys():\n",
    "        for fn in list(train_feats[let].keys())[:eg_ct]:\n",
    "            pts = train_feats[let][fn]\n",
    "            x_pts = [v[0] for v in pts]\n",
    "            y_pts = [v[1] for v in pts]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.scatter(x_pts,y_pts)\n",
    "            plt.title(f\"Plot of character {let} from file {fn}\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Templates Built\n"
     ]
    }
   ],
   "source": [
    "templ = getTemplates(train_feats, angle=hwr_angle)\n",
    "print(\"Templates Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev 70 prediction: a\n",
      "Dev 71 prediction: a\n",
      "Dev 72 prediction: a\n",
      "Dev 73 prediction: a\n",
      "Dev 74 prediction: a\n",
      "Dev 75 prediction: a\n",
      "Dev 76 prediction: a\n",
      "Dev 77 prediction: a\n",
      "Dev 78 prediction: a\n",
      "Dev 79 prediction: a\n",
      "Dev 80 prediction: a\n",
      "Dev 81 prediction: a\n",
      "Dev 82 prediction: a\n",
      "Dev 83 prediction: a\n",
      "Dev 84 prediction: a\n",
      "Dev 85 prediction: a\n",
      "Dev 86 prediction: a\n",
      "Dev 87 prediction: a\n",
      "Dev 88 prediction: a\n",
      "Dev 89 prediction: a\n",
      "Dev 70 prediction: ai\n",
      "Dev 71 prediction: ai\n",
      "Dev 72 prediction: ai\n",
      "Dev 73 prediction: ai\n",
      "Dev 74 prediction: ai\n",
      "Dev 75 prediction: ai\n",
      "Dev 76 prediction: ai\n",
      "Dev 77 prediction: ai\n",
      "Dev 78 prediction: ai\n",
      "Dev 79 prediction: ai\n",
      "Dev 80 prediction: ai\n",
      "Dev 81 prediction: ai\n",
      "Dev 82 prediction: ai\n",
      "Dev 83 prediction: ai\n",
      "Dev 84 prediction: ai\n",
      "Dev 85 prediction: ai\n",
      "Dev 86 prediction: ai\n",
      "Dev 87 prediction: ai\n",
      "Dev 88 prediction: ai\n",
      "Dev 89 prediction: ai\n",
      "Dev 67 prediction: bA\n",
      "Dev 68 prediction: bA\n",
      "Dev 69 prediction: bA\n",
      "Dev 70 prediction: chA\n",
      "Failed, true: bA, pred: chA\n",
      "Dev 71 prediction: bA\n",
      "Dev 72 prediction: bA\n",
      "Dev 73 prediction: bA\n",
      "Dev 74 prediction: bA\n",
      "Dev 75 prediction: bA\n",
      "Dev 76 prediction: bA\n",
      "Dev 77 prediction: bA\n",
      "Dev 78 prediction: bA\n",
      "Dev 79 prediction: bA\n",
      "Dev 80 prediction: bA\n",
      "Dev 81 prediction: bA\n",
      "Dev 82 prediction: bA\n",
      "Dev 83 prediction: bA\n",
      "Dev 84 prediction: bA\n",
      "Dev 85 prediction: bA\n",
      "Dev 86 prediction: bA\n",
      "Dev 70 prediction: chA\n",
      "Dev 71 prediction: chA\n",
      "Dev 72 prediction: chA\n",
      "Dev 73 prediction: chA\n",
      "Dev 74 prediction: chA\n",
      "Dev 75 prediction: chA\n",
      "Dev 76 prediction: chA\n",
      "Dev 77 prediction: chA\n",
      "Dev 78 prediction: chA\n",
      "Dev 79 prediction: chA\n",
      "Dev 80 prediction: chA\n",
      "Dev 81 prediction: chA\n",
      "Dev 82 prediction: chA\n",
      "Dev 83 prediction: chA\n",
      "Dev 84 prediction: chA\n",
      "Dev 85 prediction: chA\n",
      "Dev 86 prediction: chA\n",
      "Dev 87 prediction: chA\n",
      "Dev 88 prediction: chA\n",
      "Dev 89 prediction: bA\n",
      "Failed, true: chA, pred: bA\n",
      "Dev 69 prediction: dA\n",
      "Dev 70 prediction: dA\n",
      "Dev 71 prediction: dA\n",
      "Dev 72 prediction: dA\n",
      "Dev 73 prediction: dA\n",
      "Dev 74 prediction: dA\n",
      "Dev 75 prediction: dA\n",
      "Dev 76 prediction: dA\n",
      "Dev 77 prediction: dA\n",
      "Dev 78 prediction: dA\n",
      "Dev 79 prediction: dA\n",
      "Dev 80 prediction: dA\n",
      "Dev 81 prediction: chA\n",
      "Failed, true: dA, pred: chA\n",
      "Dev 82 prediction: dA\n",
      "Dev 83 prediction: dA\n",
      "Dev 84 prediction: dA\n",
      "Dev 85 prediction: dA\n",
      "Dev 86 prediction: dA\n",
      "Dev 87 prediction: dA\n",
      "Dev 88 prediction: dA\n",
      "Acc: 0.97\n",
      "Time taken: 8.2220 sec\n"
     ]
    }
   ],
   "source": [
    "predictCWRT(train_feats, dev_feats, angle=hwr_angle)\n",
    "# predict(train_feats, dev_feats, angle=hwr_angle)\n",
    "\n",
    "# CWRT only angle, bad diff     --      98%\n",
    "# Direct, only angle, bad diff  --      98%\n",
    "# CWRT only angle, good diff    --      97%\n",
    "# Direct only angle, good diff  --      99%\n",
    "# CWRT, x,y mean,std normed     --      93%\n",
    "# Direct, x,y mean,std normed   --      98%\n",
    "# CWRT x,y                      --      73%\n",
    "# Direct x,y                    --      82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrete HMM\n",
    "\n",
    "# 1. Use vector quantization (k-means) to convert feature vecs to symbols\n",
    "# 2. Store train and test symbol seqs in files\n",
    "# 3. Use HMM C++ code to train on train seqs, build model\n",
    "# 4. Use HMM C++ code to eval trained model on test seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Quantization using k-means\n",
    "\n",
    "def k_means(data,k=15):\n",
    "    # reshape data for numpy broadcasting\n",
    "    data = np.reshape(data,[-1,1,data.shape[-1]])\n",
    "    # initialize k means with random means\n",
    "    myrange = np.linspace(0,data.shape[0]-1,k,dtype = np.int64)\n",
    "    kmeans = np.vstack([data[myrange,0,i] for i in range(0,data.shape[-1])]).T\n",
    "    # reshape data for numpy broadcasting\n",
    "    kmeans = np.reshape(kmeans,[1,-1,kmeans.shape[-1]])\n",
    "    # calculate distances\n",
    "    dists = np.sum((data - kmeans)**2,axis=2)\n",
    "    # initialize cluster assignments\n",
    "    \n",
    "    # choose n rows from a kxk identity matrix \n",
    "    # using an nx1 argmin matrix (ranging from 0 to k-1)\n",
    "    # to produce an nxk 1-hot encoded matrix\n",
    "    r_nk_old = np.eye(k)[np.argmin(dists,axis=1)]\n",
    "    r_nk_new = r_nk_old.copy()\n",
    "    c = 0\n",
    "    while True:\n",
    "        #print(f\"Iteration {c}\")\n",
    "        c+=1\n",
    "        # move cluster assignments into old variable for comparison\n",
    "        r_nk_old = r_nk_new.copy()\n",
    "        # update means\n",
    "        if np.any(np.sum(r_nk_old,axis=0) == 0):\n",
    "            print(r_nk_old)\n",
    "            print(\"error, 0 sum encountered\")\n",
    "            break\n",
    "        kmeans = (r_nk_old.T @ np.squeeze(data))/np.reshape(np.sum(r_nk_old,axis=0),[-1,1])\n",
    "        # update new cluster assignments\n",
    "        dists = np.sum((data - kmeans)**2,axis=2)\n",
    "        r_nk_new = np.eye(k)[np.argmin(dists,axis=1)]\n",
    "        # test for convergence\n",
    "        if np.all(r_nk_old == r_nk_new):\n",
    "            break\n",
    "    print(f\"Iterations to convergence = {c}\")\n",
    "    return kmeans, r_nk_new\n",
    "\n",
    "def k_means_sklearn(feats, k=10):\n",
    "    '''\n",
    "    Performs k-means on elements of feats, returns cluster centres\n",
    "    '''\n",
    "\n",
    "    km_inst = cluster.KMeans(n_clusters=k, random_state=1)\n",
    "    km_inst.fit(feats)\n",
    "    return km_inst.cluster_centers_, km_inst.labels_\n",
    "\n",
    "def quantize_with_means(feats, means):\n",
    "    '''\n",
    "    Quantizes each example, given k-means centres\n",
    "    '''\n",
    "\n",
    "    labels = []\n",
    "    for feat in feats:\n",
    "        for m_id in range(len(means)):\n",
    "            norm_here = np.linalg.norm(feat-means[m_id])\n",
    "            if norm_here < min_norm:\n",
    "                min_norm = norm_here\n",
    "                feat_sym = m_id\n",
    "        labels.append(feat_sym)\n",
    "    return labels\n",
    "\n",
    "def quantize_train(train_feats):\n",
    "    '''\n",
    "    Quantizes real valued vectors into symbols derived from k-means cluster centres\n",
    "    '''\n",
    "\n",
    "    # Take all vectors across files for particular class. Do k-means on that\n",
    "    # For eg in handwriting, this means -- take one letter, do k-means on all instances of that letter\n",
    "\n",
    "    means = {}\n",
    "    syms = {}\n",
    "    for cl in train_feats.keys():\n",
    "        means[cl] = None\n",
    "        syms[cl] = {}\n",
    "        fns = sorted(list(train_feats[cl].keys()))\n",
    "        class_feats = np.vstack([train_feats[cl][fn] for fn in fns])\n",
    "        bounds = np.array([len(train_feats[cl][fn]) for fn in fns])\n",
    "        bounds = np.cumsum(bounds)\n",
    "        bd_dict = {fns[i]:bounds[i] for i in range(len(fns))}\n",
    "        means[cl], labels_here = k_means(class_feats, k=10)\n",
    "        syms[cl] = {fn:labels_here[bd_dict[fn]] for fn in fns}\n",
    "    \n",
    "    return syms, means\n",
    "\n",
    "def write_syms(syms, pref='dummy'):\n",
    "    '''\n",
    "    Write quantized symbols into seq file for HMM C++\n",
    "    Set pref to 'train' or 'dev'\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        os.mkdir(f'./HMM-Code/{pref}')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    for cl in syms.keys():\n",
    "        out_str = \"\"\n",
    "        for fn in syms[cl].keys():\n",
    "            out_str += \" \".join(str(char) for char in syms[cl][fn])\n",
    "            out_str += \"\\n\"\n",
    "\n",
    "        with open(f'./{pref}/{cl}.txt', 'w') as fo:\n",
    "            fo.write(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC HMM\n",
    "\n",
    "# Quantized\n",
    "syms_train, means_train = quantize_train(train_feats)\n",
    "syms_dev = quantize_with_means(dev_feats, means_train)\n",
    "\n",
    "# Write symbols to sequences file for HMM C++\n",
    "write_syms(syms_train, 'mfcc_train')\n",
    "write_syms(syms_dev, 'mfcc_dev')\n",
    "\n",
    "# Set initial params for each class-specific HMM\n",
    "# Assume left-to-right HMM, and each state modelled by unimodal Gaussian\n",
    "# So num_states = num_symbols = k in k-means used earlier to cluster vectors \n",
    "\n",
    "\n",
    "# Call HMM C++ trainer, get trained models for each class\n",
    "\n",
    "# Test on dev seqs, get probabs from each HMM, predict with argmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "\n",
    "# TODO MFCC HMM\n",
    "# TODO HWR HMM\n",
    "# TODO Connected Spoken Digits\n",
    "# TODO Connected Handwritten Characters\n",
    "# TODO ROC, DET, Confusion Matrices for all 4 + 2 optional tasks"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f06a5a6c72c548a274458fa17d091e69325cd9ba59456ad7c1d1704c3a0d1f5e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cs5691_prml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
